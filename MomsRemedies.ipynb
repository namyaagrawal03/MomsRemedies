{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namyaagrawal03/MomsRemedies/blob/main/MomsRemedies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndVra59YRdzB"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet\n",
        "import json\n",
        "from nltk.tokenize import word_tokenize\n",
        "import random\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NC3TF53oQgzd"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "tag_responses=pd.read_json(\"/content/drive/MyDrive/intents (1).json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stoz26_csj7z"
      },
      "outputs": [],
      "source": [
        "# Initialize NLP\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    doc = nlp(text)\n",
        "    return \" \".join([token.lemma_ for token in doc if not token.is_punct])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcpvUZwYsmSs"
      },
      "outputs": [],
      "source": [
        "# Function to get a random response from the intent\n",
        "def get_response(intent):\n",
        "    return random.choice(intent['responses'])\n",
        "\n",
        "# Function to find synonyms using WordNet\n",
        "def get_synonyms(word):\n",
        "    synonyms = set()\n",
        "    for synset in wordnet.synsets(word):\n",
        "        for lemma in synset.lemmas():\n",
        "            synonyms.add(lemma.name())\n",
        "    return list(synonyms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71DAfK3d3iO6"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "HdmQDJ93ROuz",
        "outputId": "c8ea9349-23ba-46b1-b510-3214abae1442"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-e9da79eb36c8>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Assuming you have a DataFrame named tag_responses with 'patterns' and 'intents' columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tag'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Assuming 'patterns' contains user inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'responses'\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# Assuming 'intents' contains the corresponding labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'intent' is not defined"
          ]
        }
      ],
      "source": [
        "# Main chat function\n",
        "'''def chat():\n",
        "    print(\"Chatbot: Hello! How can I help you today?\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        user_input = preprocess_text(user_input)\n",
        "        tokens = word_tokenize(user_input)\n",
        "\n",
        "        exit_phrases = {\"exit\", \"bye\", \"see you later\", \"goodbye\", \"no\", \"thank you\", \"thanks\"}\n",
        "\n",
        "    #checking if any exit phrases are in the user input\n",
        "        if any (phrase in tokens for phrase in exit_phrases):\n",
        "            print(\"Chatbot: Goodbye, have a nice day !\")\n",
        "            break\n",
        "\n",
        "        found_intent = None\n",
        "        for intent in tag_responses[\"intents\"]:\n",
        "            for pattern in intent[\"patterns\"]:\n",
        "                for token in tokens:\n",
        "                    if token in pattern.split() or token in get_synonyms(pattern):\n",
        "                        found_intent = intent\n",
        "                        break\n",
        "\n",
        "        if found_intent:\n",
        "            response = get_response(found_intent)\n",
        "            print(\"Chatbot:\", response)\n",
        "        else:\n",
        "            print(\"Chatbot: Sorry, I cannot recommend you remedies based on your input\")\n",
        "            break\n",
        "'''\n",
        "# Load your dataset and prepare it for training\n",
        "# Assuming you have a DataFrame named tag_responses with 'patterns' and 'intents' columns\n",
        "\n",
        "X = ['tag']  # Assuming 'patterns' contains user inputs\n",
        "y = intent['responses']   # Assuming 'intents' contains the corresponding labels\n",
        "\n",
        "# Initialize and fit a TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X = tfidf_vectorizer.fit_transform(X)\n",
        "\n",
        "# Rest of the code remains the same\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=4)\n",
        "\n",
        "# Create and train a Decision Tree classifier\n",
        "decision_tree_classifier = DecisionTreeClassifier()\n",
        "decision_tree_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Modify your chat function\n",
        "def chat():\n",
        "    print(\"Chatbot: Hello! How can I help you today?\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        user_input = preprocess_text(user_input)\n",
        "        # Transform user input into TF-IDF features\n",
        "        user_input_features = tfidf_vectorizer.transform([user_input])\n",
        "\n",
        "        exit_phrases = {\"exit\", \"bye\", \"see you later\", \"goodbye\", \"no\", \"thank you\", \"thanks\"}\n",
        "\n",
        "        if any(phrase in user_input for phrase in exit_phrases):\n",
        "            print(\"Chatbot: Goodbye, have a nice day!\")\n",
        "            break\n",
        "\n",
        "        # Predict the intent using the Decision Tree classifier\n",
        "        intent = decision_tree_classifier.predict(user_input_features)\n",
        "        found_intent = tag_responses[\"intents\"][intent]\n",
        "\n",
        "        response = get_response(found_intent)\n",
        "        print(\"Chatbot:\", response)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KmjZL-sspLs",
        "outputId": "70504270-33a4-4ec2-c5f7-237999980648"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot: Hello! How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    chat()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWGe7zwHstiM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPayypOAdml8d66+B0nkjJs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}